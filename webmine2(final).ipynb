{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-01-27T08:30:05.363087Z",
     "iopub.status.busy": "2025-01-27T08:30:05.362741Z",
     "iopub.status.idle": "2025-01-27T08:30:31.376893Z",
     "shell.execute_reply": "2025-01-27T08:30:31.375821Z",
     "shell.execute_reply.started": "2025-01-27T08:30:05.363056Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformers\n",
      "  Downloading sentence_transformers-3.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.46.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (4.66.4)\n",
      "Requirement already satisfied: torch>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.14.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.26.2)\n",
      "Requirement already satisfied: Pillow in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (10.3.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2024.6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (4.12.2)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.3)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Downloading sentence_transformers-3.4.0-py3-none-any.whl (275 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: sentence-transformers\n",
      "Successfully installed sentence-transformers-3.4.0\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (3.2.4)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -q pandas torch scikit-learn\n",
    "!pip install sentence-transformers transformers\n",
    "!pip install nltk\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T08:30:31.379180Z",
     "iopub.status.busy": "2025-01-27T08:30:31.378884Z",
     "iopub.status.idle": "2025-01-27T08:30:31.788217Z",
     "shell.execute_reply": "2025-01-27T08:30:31.787327Z",
     "shell.execute_reply.started": "2025-01-27T08:30:31.379151Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T08:30:31.789492Z",
     "iopub.status.busy": "2025-01-27T08:30:31.789154Z",
     "iopub.status.idle": "2025-01-27T08:31:13.897051Z",
     "shell.execute_reply": "2025-01-27T08:31:13.896119Z",
     "shell.execute_reply.started": "2025-01-27T08:30:31.789466Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                            title  \\\n",
      "0  49495844  A & B High Performance Firearms   \n",
      "1   3579086                      A & C Black   \n",
      "2  62397582            A & F Harvey Brothers   \n",
      "3  15547032                      A & G Price   \n",
      "4   8021609               A & M Karagheusian   \n",
      "\n",
      "                                                text  \\\n",
      "0  A & B High Performance Firearms was a competit...   \n",
      "1  A & C Black is a British book publishing compa...   \n",
      "2  A & F Harvey Brothers, first Spinning Cotton M...   \n",
      "3  A & G Price Limited is an engineering firm and...   \n",
      "4  thumb|right|238px|A portion of the Karagheusia...   \n",
      "\n",
      "                                          categories  \n",
      "0  [Defunct firearms manufacturers, Defunct manuf...  \n",
      "1  [Encyclopædia Britannica, Ornithological publi...  \n",
      "2                                     [Cotton mills]  \n",
      "3  [Locomotive manufacturers of New Zealand, Tham...  \n",
      "4  [1904 establishments in the United States, Arm...  \n",
      "Index(['id', 'title', 'text', 'categories'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# File paths for your Parquet files\n",
    "file_paths = [\n",
    "    '/kaggle/input/wikipedia-20230701/a.parquet',\n",
    "    '/kaggle/input/wikipedia-20230701//b.parquet',\n",
    "    '/kaggle/input/wikipedia-20230701/c.parquet'\n",
    "]\n",
    "\n",
    "# Read each file and store them in a list of DataFrames\n",
    "dfs = [pd.read_parquet(file) for file in file_paths]\n",
    "\n",
    "# Concatenate the DataFrames into one\n",
    "df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Display the first few rows\n",
    "print(df.head())\n",
    "\n",
    "# Check the columns\n",
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T08:31:13.900244Z",
     "iopub.status.busy": "2025-01-27T08:31:13.899631Z",
     "iopub.status.idle": "2025-01-27T09:43:01.395960Z",
     "shell.execute_reply": "2025-01-27T09:43:01.395113Z",
     "shell.execute_reply.started": "2025-01-27T08:31:13.900211Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b9a6469e8a9424697ce9baab11a8901",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processing Batches:   0%|          | 0/11840 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    Title: A & B High Performance Firearms. Catego...\n",
      "1    Title: A & C Black. Categories: Encyclopædia B...\n",
      "2    Title: A & F Harvey Brothers. Categories: Cott...\n",
      "3    Title: A & G Price. Categories: Locomotive man...\n",
      "4    Title: A & M Karagheusian. Categories: 1904 es...\n",
      "Name: combined, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download('stopwords')\n",
    "# Get the list of stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "\n",
    "# Combine the fields into one text column\n",
    "def combine_fields(row):\n",
    "    categories = ', '.join(row['categories'])  # Convert list to string\n",
    "    \n",
    "    # Tokenize the text\n",
    "    words = word_tokenize(row[\"text\"])\n",
    "    \n",
    "    # Remove stop words\n",
    "    filtered_text = ' '.join(list(filter(lambda word: word.lower() not in stop_words, words)))   \n",
    "    \n",
    "    return f\"Title: {row['title']}. Categories: {categories}. Text: {filtered_text}\"\n",
    "    # return f\"Title: {row['title']} Category: {row['categories']}\"\n",
    "\n",
    "\n",
    "# Batch processing function\n",
    "def batch_process(df, batch_size=100):\n",
    "    combined_results = []\n",
    "    \n",
    "    # Calculate the number of batches\n",
    "    num_batches = (len(df) // batch_size) + (1 if len(df) % batch_size != 0 else 0)\n",
    "    \n",
    "    # Process each batch with tqdm for progress tracking\n",
    "    for batch_num in tqdm(range(num_batches), desc=\"Processing Batches\"):\n",
    "        start_idx = batch_num * batch_size\n",
    "        end_idx = min((batch_num + 1) * batch_size, len(df))\n",
    "        \n",
    "        # Get the current batch\n",
    "        batch = df.iloc[start_idx:end_idx]\n",
    "        \n",
    "        # Apply the function to the batch\n",
    "        batch_results = batch.apply(combine_fields, axis=1)\n",
    "        \n",
    "        # Append the results\n",
    "        combined_results.extend(batch_results)\n",
    "    \n",
    "    return combined_results\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "# Apply the function to create a 'combined' column\n",
    "tqdm.pandas()\n",
    "df['combined'] = batch_process(df, batch_size=batch_size)\n",
    "# \n",
    "# df['combined'] = df.progress_apply(combine_fields, axis=1)\n",
    "\n",
    "# Preview the combined text\n",
    "print(df['combined'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:43:01.397420Z",
     "iopub.status.busy": "2025-01-27T09:43:01.397015Z",
     "iopub.status.idle": "2025-01-27T09:43:02.153518Z",
     "shell.execute_reply": "2025-01-27T09:43:02.152597Z",
     "shell.execute_reply.started": "2025-01-27T09:43:01.397391Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1183906 entries, 0 to 1183905\n",
      "Data columns (total 2 columns):\n",
      " #   Column    Non-Null Count    Dtype \n",
      "---  ------    --------------    ----- \n",
      " 0   id        1183906 non-null  object\n",
      " 1   combined  1183906 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 18.1+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "# Drop unnecessary columns\n",
    "df = df.drop(columns=['title', 'text', 'categories'])\n",
    "\n",
    "# Force garbage collection\n",
    "gc.collect()\n",
    "\n",
    "# Optionally reset index to clean up any lingering references\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Check DataFrame memory usage\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T09:43:02.154805Z",
     "iopub.status.busy": "2025-01-27T09:43:02.154495Z",
     "iopub.status.idle": "2025-01-27T10:27:22.287786Z",
     "shell.execute_reply": "2025-01-27T10:27:22.286861Z",
     "shell.execute_reply.started": "2025-01-27T09:43:02.154777Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "36f6e0b1628044dd992f261d56fcea5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d0753d337df4ec9b1d5c4e9a61fafc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5fc77bbf134c07a80e0d3682377674",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/10.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14e9c053e3a1419fa5771b0b661c23bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "640c5f89dafa48e187570b505ff6e710",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4faf97f3db1d4789a49fa2b5e2caf999",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "affc39216daa4c9192afbfb6e2059f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4cd49a2d03e4cb2a3793b0bb96716cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae12117d65cf4c64ac600d26c2f79cc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "797ebca19fa24288b1b0d9ab5a676dd4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b227f8f98a9745c29715411f83130705",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating Embeddings: 100%|██████████| 2313/2313 [43:46<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         id                                           combined  \\\n",
      "0  49495844  Title: A & B High Performance Firearms. Catego...   \n",
      "1   3579086  Title: A & C Black. Categories: Encyclopædia B...   \n",
      "2  62397582  Title: A & F Harvey Brothers. Categories: Cott...   \n",
      "3  15547032  Title: A & G Price. Categories: Locomotive man...   \n",
      "4   8021609  Title: A & M Karagheusian. Categories: 1904 es...   \n",
      "\n",
      "                                          embeddings  \n",
      "0  [0.005076993220085449, 0.014148154193647369, -...  \n",
      "1  [-0.020476288057262163, -0.09883869838271596, ...  \n",
      "2  [-0.08427029833660497, -0.01244955600900288, -...  \n",
      "3  [-0.10381282871141384, -0.01448750310363473, 0...  \n",
      "4  [-0.053385633809100275, -0.017941486034577337,...  \n",
      "(384,)\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.preprocessing import normalize\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(disable=True)\n",
    "# Load the SentenceTransformer model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')  # Lightweight & effective\n",
    "\n",
    "# Convert the combined text column to a list\n",
    "text_list = df['combined'].tolist()\n",
    "\n",
    "# Initialize a list to store embeddings\n",
    "embeddings = []\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 512\n",
    "tqdm.pandas(disable=True)\n",
    "\n",
    "# Use tqdm to visualize progress during batch processing\n",
    "for i in tqdm(range(0, len(text_list), batch_size), desc=\"Generating Embeddings\"):\n",
    "    # Process a batch of text\n",
    "    batch = text_list[i:i + batch_size]\n",
    "    \n",
    "    # Generate embeddings for the current batch\n",
    "    batch_embeddings = model.encode(batch, convert_to_numpy=True, show_progress_bar=False)\n",
    "    \n",
    "    # Append the batch embeddings to the main list\n",
    "    embeddings.extend(batch_embeddings)\n",
    "\n",
    "# Normalize embeddings for better similarity scores\n",
    "embedding_matrix = normalize(embeddings)\n",
    "\n",
    "# Add normalized embeddings to the DataFrame\n",
    "df['embeddings'] = list(embedding_matrix)  # Convert 2D array to a list of 1D arrays for Pandas compatibility\n",
    "\n",
    "# Print the first few rows and verify an embedding's shape\n",
    "print(df.head())\n",
    "print(df['embeddings'].iloc[0].shape)  # Should print (384,) for each embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T10:27:22.289599Z",
     "iopub.status.busy": "2025-01-27T10:27:22.288984Z",
     "iopub.status.idle": "2025-01-27T10:27:22.294390Z",
     "shell.execute_reply": "2025-01-27T10:27:22.293502Z",
     "shell.execute_reply.started": "2025-01-27T10:27:22.289569Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'combined', 'embeddings'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T10:27:22.296034Z",
     "iopub.status.busy": "2025-01-27T10:27:22.295621Z",
     "iopub.status.idle": "2025-01-27T10:27:22.315152Z",
     "shell.execute_reply": "2025-01-27T10:27:22.314309Z",
     "shell.execute_reply.started": "2025-01-27T10:27:22.295985Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>combined</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49495844</td>\n",
       "      <td>Title: A &amp; B High Performance Firearms. Catego...</td>\n",
       "      <td>[0.005076993220085449, 0.014148154193647369, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3579086</td>\n",
       "      <td>Title: A &amp; C Black. Categories: Encyclopædia B...</td>\n",
       "      <td>[-0.020476288057262163, -0.09883869838271596, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62397582</td>\n",
       "      <td>Title: A &amp; F Harvey Brothers. Categories: Cott...</td>\n",
       "      <td>[-0.08427029833660497, -0.01244955600900288, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>15547032</td>\n",
       "      <td>Title: A &amp; G Price. Categories: Locomotive man...</td>\n",
       "      <td>[-0.10381282871141384, -0.01448750310363473, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8021609</td>\n",
       "      <td>Title: A &amp; M Karagheusian. Categories: 1904 es...</td>\n",
       "      <td>[-0.053385633809100275, -0.017941486034577337,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           combined  \\\n",
       "0  49495844  Title: A & B High Performance Firearms. Catego...   \n",
       "1   3579086  Title: A & C Black. Categories: Encyclopædia B...   \n",
       "2  62397582  Title: A & F Harvey Brothers. Categories: Cott...   \n",
       "3  15547032  Title: A & G Price. Categories: Locomotive man...   \n",
       "4   8021609  Title: A & M Karagheusian. Categories: 1904 es...   \n",
       "\n",
       "                                          embeddings  \n",
       "0  [0.005076993220085449, 0.014148154193647369, -...  \n",
       "1  [-0.020476288057262163, -0.09883869838271596, ...  \n",
       "2  [-0.08427029833660497, -0.01244955600900288, -...  \n",
       "3  [-0.10381282871141384, -0.01448750310363473, 0...  \n",
       "4  [-0.053385633809100275, -0.017941486034577337,...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T10:27:22.316754Z",
     "iopub.status.busy": "2025-01-27T10:27:22.316238Z",
     "iopub.status.idle": "2025-01-27T10:27:27.285483Z",
     "shell.execute_reply": "2025-01-27T10:27:27.284590Z",
     "shell.execute_reply.started": "2025-01-27T10:27:22.316715Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance of Embeddings: 0.0024311788196501563\n"
     ]
    }
   ],
   "source": [
    "# # Check variance of embeddings\n",
    "print(f\"Variance of Embeddings: {np.var(embedding_matrix, axis=0).mean()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T10:28:12.387972Z",
     "iopub.status.busy": "2025-01-27T10:28:12.387334Z",
     "iopub.status.idle": "2025-01-27T10:28:12.393299Z",
     "shell.execute_reply": "2025-01-27T10:28:12.392422Z",
     "shell.execute_reply.started": "2025-01-27T10:28:12.387937Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def recommend_articles(input_title, top_n=10):\n",
    "    if input_title not in df['combined'].values:\n",
    "        return \"Article not found.\"\n",
    "    \n",
    "    input_idx = df.index[df['combined'] == input_title].item()\n",
    "    input_embedding = embedding_matrix[input_idx]\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarities = cosine_similarity([input_embedding], embedding_matrix).flatten()\n",
    "    \n",
    "    # Exclude the input article and get top matches\n",
    "    sorted_indices = np.argsort(similarities)[::-1]\n",
    "    valid_indices = [i for i in sorted_indices if i != input_idx][:top_n]\n",
    "    \n",
    "    return df.iloc[valid_indices]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T10:31:49.787215Z",
     "iopub.status.busy": "2025-01-27T10:31:49.786890Z",
     "iopub.status.idle": "2025-01-27T10:32:25.241853Z",
     "shell.execute_reply": "2025-01-27T10:32:25.241085Z",
     "shell.execute_reply.started": "2025-01-27T10:31:49.787187Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================= sample:  0 =========================\n",
      "input:   Acrocercops didymella. \n",
      "29525464  :  Acrocercops plebeia. \n",
      "29512977  :  Acrocercops doloploca. \n",
      "29512907  :  Acrocercops irrorata. \n",
      "29513023  :  Acrocercops grammatacma. \n",
      "29525434  :  Acrocercops trapezoides. \n",
      "29525510  :  Acrocercops plectospila. \n",
      "29525158  :  Acrocercops leucomochla. \n",
      "29484246  :  Acrocercops albomaculella. \n",
      "29525532  :  Acrocercops spodophylla. \n",
      "29512960  :  Acrocercops crucigera. \n",
      "========================= sample:  1 =========================\n",
      "input:   Arnica cernua. \n",
      "19779845  :  Arnica spathulata. \n",
      "19779735  :  Arnica sororia. \n",
      "637284  :  Arnica. \n",
      "19735580  :  Arnica latifolia. \n",
      "46779050  :  Arnica gracilis. \n",
      "35694499  :  Arnica chamissonis. \n",
      "19379141  :  Arctostaphylos canescens. \n",
      "19779979  :  Arnica venosa. \n",
      "19735997  :  Arnica nevadensis. \n",
      "21592673  :  Ceanothus pumilus. \n",
      "========================= sample:  2 =========================\n",
      "input:   Bloom (store). \n",
      "36310361  :  Belle Foods. \n",
      "843787  :  Bloomingdale's. \n",
      "7394022  :  Bloom's restaurant. \n",
      "41179568  :  Best Market. \n",
      "3546474  :  Bloomin' Brands. \n",
      "23220202  :  Bloom Brothers Department Stores. \n",
      "2002297  :  Brookshire's Food & Pharmacy. \n",
      "5315224  :  Commisso's Food Markets. \n",
      "22516880  :  Alex Lee Inc.. \n",
      "2935637  :  Affiliated Foods Southwest. \n",
      "========================= sample:  3 =========================\n",
      "input:   Choi Chul-woo. \n",
      "12018707  :  Choi Kang-hee (footballer). \n",
      "6881957  :  Choi Young-il. \n",
      "19716396  :  Cho Se-kwon. \n",
      "64606013  :  Choi Jun. \n",
      "21031080  :  Chun Jae-woon. \n",
      "30939189  :  Choi Jin-soo (footballer). \n",
      "7074534  :  Choi In-young. \n",
      "19504599  :  Choi Jae-soo. \n",
      "36277647  :  Choi Bo-kyung. \n",
      "20273157  :  Choi Yoon-yeol. \n",
      "========================= sample:  4 =========================\n",
      "input:   Blacklick, Virginia. \n",
      "6408816  :  Blacklick. \n",
      "43976593  :  Bartlick, Virginia. \n",
      "37303848  :  Bertha, Virginia. \n",
      "38235361  :  Blackwood, Virginia. \n",
      "3837653  :  Black Wolf, West Virginia. \n",
      "26700477  :  Black, West Virginia. \n",
      "32856866  :  Blackwater, Mathews County, Virginia. \n",
      "5915986  :  Blacklick, Ohio. \n",
      "17674682  :  Crockett, Virginia. \n",
      "37216474  :  Blessing, Virginia. \n",
      "========================= sample:  5 =========================\n",
      "input:   Alfred Gould (trade unionist). \n",
      "14832997  :  Billy Hull. \n",
      "46302129  :  Alfred John Stephenson. \n",
      "2703787  :  Bob Edwards (politician). \n",
      "60781070  :  Charles Flynn (trade unionist). \n",
      "60851181  :  Arthur Dawson (trade unionist). \n",
      "59954568  :  Albert Taylor (trade unionist). \n",
      "2219041  :  Alfred Waterson. \n",
      "19300874  :  Alexander Gordon Cameron. \n",
      "32059392  :  Ben Riley (politician). \n",
      "58766203  :  Bradford Labour Union. \n",
      "========================= sample:  6 =========================\n",
      "input:   Canadian Environmental Sustainability Indicators. \n",
      "14602493  :  Canadian Council of Ministers of the Environment. \n",
      "56873964  :  Context-Based Sustainability. \n",
      "10685699  :  Canadian Environmental Assessment Act, 2012. \n",
      "30034641  :  Committee on Sustainability Assessment. \n",
      "12402182  :  California Environmental Protection Agency. \n",
      "19748815  :  California Environmental Resources Evaluation System. \n",
      "49598146  :  Criteria and indicators of sustainable forest management. \n",
      "37514747  :  Climate Change Performance Index. \n",
      "44154342  :  Alberta Environment and Protected Areas. \n",
      "29592212  :  BSI PAS 2060. \n",
      "========================= sample:  7 =========================\n",
      "input:   Anticipatory democracy. \n",
      "51553282  :  Anticipatory governance. \n",
      "51812203  :  Against Democracy. \n",
      "3412680  :  Anticipatory exclusion. \n",
      "28964679  :  Collaborative e-democracy. \n",
      "1126216  :  Anticipation (artificial intelligence). \n",
      "5965331  :  Clement Bezold. \n",
      "74099814  :  Citizens’ Initiative Review. \n",
      "32810404  :  Citizens' assembly. \n",
      "45670539  :  Anti-politics. \n",
      "34407504  :  Anocracy. \n",
      "========================= sample:  8 =========================\n",
      "input:   Arthur Fulton (sport shooter). \n",
      "15440902  :  Allan Briggs. \n",
      "11668193  :  Arthur Carnell. \n",
      "11684298  :  Alexander Rogers (sport shooter). \n",
      "15440940  :  Cornelius Burdette. \n",
      "15751969  :  Charles Stewart (sport shooter). \n",
      "18060335  :  André Regaud. \n",
      "11693793  :  Alexander Maunder. \n",
      "15464151  :  André Parmentier (sport shooter). \n",
      "13376249  :  Anton Olsen (rifle shooter). \n",
      "40605136  :  Arthur Jackson (British sport shooter). \n",
      "========================= sample:  9 =========================\n",
      "input:   Chelsea Biddell. \n",
      "40424177  :  Chelsea Roffey. \n",
      "47899859  :  Alan Teasdale. \n",
      "49124082  :  Barry Hannon. \n",
      "49154596  :  Alby Newell. \n",
      "49114132  :  Alan Self. \n",
      "63819219  :  Caitlin Gould. \n",
      "48160817  :  Alan Brand. \n",
      "13358689  :  Carly Telford. \n",
      "46673205  :  Barry Teague. \n",
      "42023963  :  Beattie Goad. \n"
     ]
    }
   ],
   "source": [
    "# Test the recommendation system\n",
    "from random import randint\n",
    "for att in range(10):\n",
    "    print('='*25, \"sample: \", att, '='*25 )\n",
    "    input_article = df['combined'][randint(0, len(df))]\n",
    "    recommendations = recommend_articles(input_article)\n",
    "    # print(recommendations)\n",
    "    \n",
    "    \n",
    "    # Display recommendations\n",
    "    print(\"input:  \", input_article.split(\"Categories:\")[0].replace(\"Title: \", \"\"))\n",
    "    for idx, i in (zip(recommendations[\"id\"], recommendations[\"combined\"])):\n",
    "        print(idx, \" : \", i.split(\"Categories:\")[0].replace(\"Title: \", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-01-27T10:27:31.713344Z",
     "iopub.status.busy": "2025-01-27T10:27:31.713071Z",
     "iopub.status.idle": "2025-01-27T10:27:31.719866Z",
     "shell.execute_reply": "2025-01-27T10:27:31.719040Z",
     "shell.execute_reply.started": "2025-01-27T10:27:31.713317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1183906\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Title: Ahmed Mohamed Ahmed. Categories: 1980 births, Living people, Somalian footballers, Somalian football managers, Somalian expatriate sportspeople in Switzerland, Expatriate soccer coaches in the United States Virgin Islands, Expatriate footballers in Switzerland, FC Thun players, Somalia men's international footballers, Men's association football defenders, Expatriate footballers in Barbados, Somalian expatriate football managers, Somalian expatriate sportspeople in Barbados, Somalian expatriate sportspeople in the United States Virgin Islands, Place of birth missing (living people). Text: Ahmed Mohamed Ahmed also known Ahmed Gaab ( Arabic : أحمد محمد أحمد ; born 22 February 1980 ) Somali football coach former player . ==Coaching career== starting young age several positions Somali Football Federation 's observation department guidance then- Federation President Abdegani Saeed Arab , hired coaching knowledge football , became head coach Somalia national beach soccer team technical adviser Federation . achieved professional coaching licence first Swiss-Somali born coach Germany . previously managed Somalia national beach soccer team FC Wyler Bern Youth Team BSC Young Boys Youth team Berne Switzerland . February 2015 , appointed head coach U.S. Virgin Islands national football team . March 2017 , appointed coach Barbadian national team . ==References== Category:1980 births Category : Living people Category : Somalian footballers Category : Somalian football managers Category : Somalian expatriate sportspeople Switzerland Category : Expatriate soccer coaches United States Virgin Islands Category : Expatriate footballers Switzerland Category : FC Thun players Category : Somalia men 's international footballers Category : Men 's association football defenders Category : Expatriate footballers Barbados Category : Somalian expatriate football managers Category : Somalian expatriate sportspeople Barbados Category : Somalian expatriate sportspeople United States Virgin Islands Category : Place birth missing ( living people )\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from random import randint\n",
    "print(len(df))\n",
    "df['combined'][randint(0, len(df))]"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 3521629,
     "sourceId": 6146260,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30805,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
